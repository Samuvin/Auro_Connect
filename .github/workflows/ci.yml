name: ğŸ”„ Continuous Integration

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:
    inputs:
      skip_lint:
        description: 'Skip Linting'
        required: false
        default: false
        type: boolean
      skip_unit_tests:
        description: 'Skip Unit Tests'
        required: false
        default: false
        type: boolean
      skip_snapshot_tests:
        description: 'Skip Snapshot Tests'
        required: false
        default: false
        type: boolean
      skip_memory_leak_tests:
        description: 'Skip Memory Leak Tests'
        required: false
        default: false
        type: boolean
      skip_performance_tests:
        description: 'Skip Performance Tests'
        required: false
        default: false
        type: boolean
      skip_e2e_tests:
        description: 'Skip End-to-End Tests'
        required: false
        default: false
        type: boolean
      skip_integration_tests:
        description: 'Skip Integration Tests'
        required: false
        default: false
        type: boolean

env:
  NODE_VERSION: '18'
  SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

jobs:
  # ========================================================================================
  # STAGE 1: SETUP & DEPENDENCIES
  # ========================================================================================
  setup:
    name: ğŸ“¦ Setup & Install Dependencies
    runs-on: ubuntu-latest
    outputs:
      cache-hit: ${{ steps.cache-deps.outputs.cache-hit }}
    steps:
      - name: ğŸ” Checkout Repository
        uses: actions/checkout@v4

      - name: ğŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ğŸ“¦ Cache Dependencies
        id: cache-deps
        uses: actions/cache@v4
        with:
          path: |
            ~/.npm
            frontend/node_modules
            backend/node_modules
            ~/.cache/ms-playwright
          key: ${{ runner.os }}-node-${{ env.NODE_VERSION }}-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-node-${{ env.NODE_VERSION }}-

      - name: ğŸ”¨ Install Root Dependencies
        if: steps.cache-deps.outputs.cache-hit != 'true'
        run: npm ci

      - name: ğŸ”¨ Install Frontend Dependencies
        if: steps.cache-deps.outputs.cache-hit != 'true'
        working-directory: frontend
        run: |
          npm ci
          npx playwright install

      - name: ğŸ”¨ Install Backend Dependencies
        if: steps.cache-deps.outputs.cache-hit != 'true'
        working-directory: backend
        run: npm ci

  # ========================================================================================
  # STAGE 2: LINTING & CODE QUALITY
  # ========================================================================================
  lint:
    name: ğŸ” Lint & Code Quality
    runs-on: ubuntu-latest
    needs: setup
    if: github.event.inputs.skip_lint != 'true'
    outputs:
      frontend-warnings: ${{ steps.lint-frontend.outputs.warnings }}
      frontend-errors: ${{ steps.lint-frontend.outputs.errors }}
      backend-warnings: ${{ steps.lint-backend.outputs.warnings }}
      backend-errors: ${{ steps.lint-backend.outputs.errors }}
    steps:
      - name: ğŸ” Checkout Repository
        uses: actions/checkout@v4

      - name: ğŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ğŸ“¦ Restore Dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.npm
            frontend/node_modules
            backend/node_modules
          key: ${{ runner.os }}-node-${{ env.NODE_VERSION }}-${{ hashFiles('**/package-lock.json') }}

      - name: ğŸ” Run Frontend ESLint
        id: lint-frontend
        working-directory: frontend
        run: |
          npm run lint:check 2>&1 | tee eslint-output.log || true
          WARNINGS=$(grep -c "warning" eslint-output.log || echo "0")
          ERRORS=$(grep -c "error" eslint-output.log || echo "0")
          echo "warnings=$WARNINGS" >> $GITHUB_OUTPUT
          echo "errors=$ERRORS" >> $GITHUB_OUTPUT
          echo "Frontend: $WARNINGS warnings, $ERRORS errors"
          if [ "$ERRORS" -gt "0" ]; then exit 1; fi

      - name: ğŸ” Run Backend ESLint
        id: lint-backend
        working-directory: backend
        run: |
          npm run lint:check 2>&1 | tee eslint-output.log || true
          WARNINGS=$(grep -c "warning" eslint-output.log || echo "0")
          ERRORS=$(grep -c "error" eslint-output.log || echo "0")
          echo "warnings=$WARNINGS" >> $GITHUB_OUTPUT
          echo "errors=$ERRORS" >> $GITHUB_OUTPUT
          echo "Backend: $WARNINGS warnings, $ERRORS errors"
          if [ "$ERRORS" -gt "0" ]; then exit 1; fi

      - name: ğŸ“Š Upload Lint Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: lint-results
          path: |
            frontend/eslint-output.log
            backend/eslint-output.log
          retention-days: 30

  # ========================================================================================
  # STAGE 3: UNIT TESTS
  # ========================================================================================
  unit-tests:
    name: ğŸ§ª Unit Tests
    runs-on: ubuntu-latest
    needs: [setup, lint]
    if: always() && github.event.inputs.skip_unit_tests != 'true'
    outputs:
      frontend-coverage: ${{ steps.test-frontend.outputs.coverage }}
      frontend-tests-passed: ${{ steps.test-frontend.outputs.passed }}
      frontend-tests-failed: ${{ steps.test-frontend.outputs.failed }}
      frontend-tests-total: ${{ steps.test-frontend.outputs.total }}
      backend-coverage: ${{ steps.test-backend.outputs.coverage }}
      backend-tests-passed: ${{ steps.test-backend.outputs.passed }}
      backend-tests-failed: ${{ steps.test-backend.outputs.failed }}
      backend-tests-total: ${{ steps.test-backend.outputs.total }}
    steps:
      - name: ğŸ” Checkout Repository
        uses: actions/checkout@v4

      - name: ğŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ğŸ“¦ Restore Dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.npm
            frontend/node_modules
            backend/node_modules
          key: ${{ runner.os }}-node-${{ env.NODE_VERSION }}-${{ hashFiles('**/package-lock.json') }}

      - name: ğŸ§ª Run Frontend Unit Tests
        id: test-frontend
        working-directory: frontend
        run: |
          npm run test:ci 2>&1 | tee test-output.log
          
          # Parse Jest output for test counts
          PASSED=$(grep -oP 'Tests:\s+\K\d+(?=\s+passed)' test-output.log || echo "0")
          FAILED=$(grep -oP 'Tests:\s+\d+\s+passed,\s+\K\d+(?=\s+failed)' test-output.log || echo "0")
          TOTAL=$(grep -oP 'Tests:\s+\K\d+(?=\s+total)' test-output.log || echo "0")
          
          # Parse coverage
          if [ -f "coverage/coverage-summary.json" ]; then
            COVERAGE=$(node -e "
              const fs = require('fs');
              try {
                const coverage = JSON.parse(fs.readFileSync('coverage/coverage-summary.json', 'utf8'));
                console.log(Math.round(coverage.total.lines.pct));
              } catch(e) {
                console.log('0');
              }
            ")
          else
            COVERAGE="0"
          fi
          
          echo "passed=$PASSED" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          echo "total=$TOTAL" >> $GITHUB_OUTPUT
          echo "coverage=$COVERAGE" >> $GITHUB_OUTPUT
          
          echo "Frontend Tests: $PASSED passed, $FAILED failed, $TOTAL total, $COVERAGE% coverage"

      - name: ğŸ§ª Run Backend Unit Tests
        id: test-backend
        working-directory: backend
        run: |
          npm run test:coverage 2>&1 | tee test-output.log
          
          # Parse Jest output for test counts
          PASSED=$(grep -oP 'Tests:\s+\K\d+(?=\s+passed)' test-output.log || echo "0")
          FAILED=$(grep -oP 'Tests:\s+\d+\s+passed,\s+\K\d+(?=\s+failed)' test-output.log || echo "0")
          TOTAL=$(grep -oP 'Tests:\s+\K\d+(?=\s+total)' test-output.log || echo "0")
          
          # Parse coverage
          if [ -f "coverage/coverage-summary.json" ]; then
            COVERAGE=$(node -e "
              const fs = require('fs');
              try {
                const coverage = JSON.parse(fs.readFileSync('coverage/coverage-summary.json', 'utf8'));
                console.log(Math.round(coverage.total.lines.pct));
              } catch(e) {
                console.log('0');
              }
            ")
          else
            COVERAGE="0"
          fi
          
          echo "passed=$PASSED" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          echo "total=$TOTAL" >> $GITHUB_OUTPUT
          echo "coverage=$COVERAGE" >> $GITHUB_OUTPUT
          
          echo "Backend Tests: $PASSED passed, $FAILED failed, $TOTAL total, $COVERAGE% coverage"

      - name: ğŸ“Š Upload Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: unit-test-results
          path: |
            frontend/coverage/
            backend/coverage/
            frontend/test-output.log
            backend/test-output.log
          retention-days: 30

  # ========================================================================================
  # STAGE 4: INTEGRATION TESTS
  # ========================================================================================
  integration-tests:
    name: ğŸ”— Integration Tests
    runs-on: ubuntu-latest
    needs: [setup, lint, unit-tests]
    if: always() && github.event.inputs.skip_integration_tests != 'true'
    outputs:
      frontend-passed: ${{ steps.integration-frontend.outputs.passed }}
      frontend-failed: ${{ steps.integration-frontend.outputs.failed }}
      frontend-total: ${{ steps.integration-frontend.outputs.total }}
      backend-passed: ${{ steps.integration-backend.outputs.passed }}
      backend-failed: ${{ steps.integration-backend.outputs.failed }}
      backend-total: ${{ steps.integration-backend.outputs.total }}
    steps:
      - name: ğŸ” Checkout Repository
        uses: actions/checkout@v4

      - name: ğŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ğŸ“¦ Restore Dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.npm
            frontend/node_modules
            backend/node_modules
            ~/.cache/ms-playwright
          key: ${{ runner.os }}-node-${{ env.NODE_VERSION }}-${{ hashFiles('**/package-lock.json') }}

      - name: ğŸ”— Run Frontend Integration Tests
        id: integration-frontend
        working-directory: frontend
        run: |
          npm run test:integration:ci 2>&1 | tee integration-output.log || true
          
          # Parse Playwright output
          PASSED=$(grep -oP '\K\d+(?=\s+passed)' integration-output.log | tail -1 || echo "0")
          FAILED=$(grep -oP '\K\d+(?=\s+failed)' integration-output.log | tail -1 || echo "0")
          TOTAL=$((PASSED + FAILED))
          
          echo "passed=$PASSED" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          echo "total=$TOTAL" >> $GITHUB_OUTPUT
          
          echo "Frontend Integration: $PASSED passed, $FAILED failed"
          if [ "$FAILED" -gt "0" ]; then exit 1; fi

      - name: ğŸ”— Run Backend Integration Tests
        id: integration-backend
        working-directory: backend
        run: |
          npm run test:integration:ci 2>&1 | tee integration-output.log || true
          
          # Parse Jest output
          PASSED=$(grep -oP 'Tests:\s+\K\d+(?=\s+passed)' integration-output.log || echo "0")
          FAILED=$(grep -oP 'Tests:\s+\d+\s+passed,\s+\K\d+(?=\s+failed)' integration-output.log || echo "0")
          TOTAL=$(grep -oP 'Tests:\s+\K\d+(?=\s+total)' integration-output.log || echo "0")
          
          echo "passed=$PASSED" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          echo "total=$TOTAL" >> $GITHUB_OUTPUT
          
          echo "Backend Integration: $PASSED passed, $FAILED failed"
          if [ "$FAILED" -gt "0" ]; then exit 1; fi

      - name: ğŸ“Š Upload Integration Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: integration-test-results
          path: |
            frontend/integration-output.log
            backend/integration-output.log
            frontend/test-results/
            frontend/playwright-report/
          retention-days: 30

  # ========================================================================================
  # STAGE 5: SNAPSHOT TESTS
  # ========================================================================================
  snapshot-tests:
    name: ğŸ“¸ Snapshot Tests
    runs-on: ubuntu-latest
    needs: [setup, lint, integration-tests]
    if: always() && github.event.inputs.skip_snapshot_tests != 'true'
    outputs:
      frontend-passed: ${{ steps.snapshot-frontend.outputs.passed }}
      frontend-failed: ${{ steps.snapshot-frontend.outputs.failed }}
      backend-passed: ${{ steps.snapshot-backend.outputs.passed }}
      backend-failed: ${{ steps.snapshot-backend.outputs.failed }}
    steps:
      - name: ğŸ” Checkout Repository
        uses: actions/checkout@v4

      - name: ğŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ğŸ“¦ Restore Dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.npm
            frontend/node_modules
            backend/node_modules
          key: ${{ runner.os }}-node-${{ env.NODE_VERSION }}-${{ hashFiles('**/package-lock.json') }}

      - name: ğŸ“¸ Run Frontend Snapshot Tests
        id: snapshot-frontend
        working-directory: frontend
        run: |
          npm run test:snapshot:ci 2>&1 | tee snapshot-output.log || true
          
          PASSED=$(grep -oP 'Tests:\s+\K\d+(?=\s+passed)' snapshot-output.log || echo "0")
          FAILED=$(grep -oP 'Tests:\s+\d+\s+passed,\s+\K\d+(?=\s+failed)' snapshot-output.log || echo "0")
          
          echo "passed=$PASSED" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          
          echo "Frontend Snapshots: $PASSED passed, $FAILED failed"
          if [ "$FAILED" -gt "0" ]; then exit 1; fi

      - name: ğŸ“¸ Run Backend Snapshot Tests
        id: snapshot-backend
        working-directory: backend
        run: |
          npm run test:snapshot:ci 2>&1 | tee snapshot-output.log || true
          
          PASSED=$(grep -oP 'Tests:\s+\K\d+(?=\s+passed)' snapshot-output.log || echo "0")
          FAILED=$(grep -oP 'Tests:\s+\d+\s+passed,\s+\K\d+(?=\s+failed)' snapshot-output.log || echo "0")
          
          echo "passed=$PASSED" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          
          echo "Backend Snapshots: $PASSED passed, $FAILED failed"
          if [ "$FAILED" -gt "0" ]; then exit 1; fi

  # ========================================================================================
  # STAGE 6: MEMORY LEAK TESTS
  # ========================================================================================
  memory-leak-tests:
    name: ğŸ§  Memory Leak Tests
    runs-on: ubuntu-latest
    needs: [setup, lint, unit-tests, integration-tests]
    if: always() && github.event.inputs.skip_memory_leak_tests != 'true'
    outputs:
      tests-passed: ${{ steps.memory-tests.outputs.passed }}
      tests-failed: ${{ steps.memory-tests.outputs.failed }}
      memory-usage: ${{ steps.memory-tests.outputs.memory_usage }}
      leaks-detected: ${{ steps.memory-tests.outputs.leaks_detected }}
    steps:
      - name: ğŸ” Checkout Repository
        uses: actions/checkout@v4

      - name: ğŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ğŸ“¦ Restore Dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.npm
            frontend/node_modules
            backend/node_modules
            ~/.cache/ms-playwright
          key: ${{ runner.os }}-node-${{ env.NODE_VERSION }}-${{ hashFiles('**/package-lock.json') }}

      - name: ğŸš€ Start Backend Server
        working-directory: backend
        run: |
          nohup npm start > ../backend-memory.log 2>&1 & echo $! > ../backend-memory.pid

      - name: ğŸŒ Start Frontend Server
        working-directory: frontend
        run: |
          nohup npm run preview > ../frontend-memory.log 2>&1 & echo $! > ../frontend-memory.pid

      - name: â³ Wait for Servers
        run: sleep 15

      - name: ğŸ§  Run Memory Leak Tests
        id: memory-tests
        working-directory: frontend
        run: |
          npm run test:memory-leaks:ci 2>&1 | tee memory-output.log || true
          
          # Parse memory test results
          PASSED=$(grep -oP '\K\d+(?=\s+passed)' memory-output.log | tail -1 || echo "0")
          FAILED=$(grep -oP '\K\d+(?=\s+failed)' memory-output.log | tail -1 || echo "0")
          
          # Extract memory usage info (if available in logs)
          MEMORY_USAGE=$(grep -oP 'Memory usage:\s+\K[\d.]+\s*MB' memory-output.log | tail -1 || echo "N/A")
          LEAKS_DETECTED=$(grep -c "Memory leak detected" memory-output.log || echo "0")
          
          echo "passed=$PASSED" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          echo "memory_usage=$MEMORY_USAGE" >> $GITHUB_OUTPUT
          echo "leaks_detected=$LEAKS_DETECTED" >> $GITHUB_OUTPUT
          
          echo "Memory Tests: $PASSED passed, $FAILED failed, $LEAKS_DETECTED leaks detected"
          if [ "$FAILED" -gt "0" ] || [ "$LEAKS_DETECTED" -gt "0" ]; then exit 1; fi

      - name: ğŸ§¹ Cleanup Servers
        if: always()
        run: |
          if [ -f backend-memory.pid ]; then
            kill $(cat backend-memory.pid) || true
            rm backend-memory.pid
          fi
          if [ -f frontend-memory.pid ]; then
            kill $(cat frontend-memory.pid) || true
            rm frontend-memory.pid
          fi

      - name: ğŸ“Š Upload Memory Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: memory-leak-test-results
          path: |
            frontend/memory-output.log
            frontend/test-results/
            backend-memory.log
            frontend-memory.log
          retention-days: 30

  # ========================================================================================
  # STAGE 7: PERFORMANCE TESTS
  # ========================================================================================
  performance-tests:
    name: âš¡ Performance Tests
    runs-on: ubuntu-latest
    needs: [setup, lint, unit-tests, integration-tests]
    if: always() && github.event.inputs.skip_performance_tests != 'true'
    outputs:
      performance-score: ${{ steps.perf-tests.outputs.performance_score }}
      accessibility-score: ${{ steps.perf-tests.outputs.accessibility_score }}
      seo-score: ${{ steps.perf-tests.outputs.seo_score }}
      best-practices-score: ${{ steps.perf-tests.outputs.best_practices_score }}
      lcp-score: ${{ steps.perf-tests.outputs.lcp_score }}
      fid-score: ${{ steps.perf-tests.outputs.fid_score }}
      cls-score: ${{ steps.perf-tests.outputs.cls_score }}
      tests-passed: ${{ steps.perf-tests.outputs.passed }}
      tests-failed: ${{ steps.perf-tests.outputs.failed }}
    steps:
      - name: ğŸ” Checkout Repository
        uses: actions/checkout@v4

      - name: ğŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ğŸ“¦ Restore Dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.npm
            frontend/node_modules
            backend/node_modules
            ~/.cache/ms-playwright
          key: ${{ runner.os }}-node-${{ env.NODE_VERSION }}-${{ hashFiles('**/package-lock.json') }}

      - name: ğŸš€ Start Backend Server
        working-directory: backend
        run: |
          nohup npm start > ../backend-perf.log 2>&1 & echo $! > ../backend-perf.pid

      - name: ğŸŒ Start Frontend Server
        working-directory: frontend
        run: |
          nohup npm run preview > ../frontend-perf.log 2>&1 & echo $! > ../frontend-perf.pid

      - name: â³ Wait for Servers
        run: sleep 15

      - name: ğŸ­ Run Performance Tests
        working-directory: frontend
        run: |
          npm run test:perf:ci 2>&1 | tee perf-output.log || true

      - name: ğŸ” Run Lighthouse Tests
        id: perf-tests
        working-directory: frontend
        run: |
          npm run test:lighthouse:ci 2>&1 | tee lighthouse-output.log || true
          
          # Parse Playwright test results
          PASSED=$(grep -oP '\K\d+(?=\s+passed)' perf-output.log | tail -1 || echo "0")
          FAILED=$(grep -oP '\K\d+(?=\s+failed)' perf-output.log | tail -1 || echo "0")
          
          # Parse Lighthouse scores from latest summary file
          if [ -f "lighthouse-reports/"*"-summary.json" ]; then
            LATEST_SUMMARY=$(ls -t lighthouse-reports/*-summary.json | head -1)
            PERF_SCORE=$(node -e "
              const fs = require('fs');
              try {
                const data = JSON.parse(fs.readFileSync('$LATEST_SUMMARY', 'utf8'));
                console.log(data.scores.performance || 0);
              } catch(e) { console.log('0'); }
            ")
            ACCESSIBILITY_SCORE=$(node -e "
              const fs = require('fs');
              try {
                const data = JSON.parse(fs.readFileSync('$LATEST_SUMMARY', 'utf8'));
                console.log(data.scores.accessibility || 0);
              } catch(e) { console.log('0'); }
            ")
            SEO_SCORE=$(node -e "
              const fs = require('fs');
              try {
                const data = JSON.parse(fs.readFileSync('$LATEST_SUMMARY', 'utf8'));
                console.log(data.scores.seo || 0);
              } catch(e) { console.log('0'); }
            ")
            BEST_PRACTICES_SCORE=$(node -e "
              const fs = require('fs');
              try {
                const data = JSON.parse(fs.readFileSync('$LATEST_SUMMARY', 'utf8'));
                console.log(data.scores['best-practices'] || 0);
              } catch(e) { console.log('0'); }
            ")
            LCP_SCORE=$(node -e "
              const fs = require('fs');
              try {
                const data = JSON.parse(fs.readFileSync('$LATEST_SUMMARY', 'utf8'));
                console.log(data.coreWebVitals.LCP?.score || 0);
              } catch(e) { console.log('0'); }
            ")
            FID_SCORE=$(node -e "
              const fs = require('fs');
              try {
                const data = JSON.parse(fs.readFileSync('$LATEST_SUMMARY', 'utf8'));
                console.log(data.coreWebVitals.FID?.score || 0);
              } catch(e) { console.log('0'); }
            ")
            CLS_SCORE=$(node -e "
              const fs = require('fs');
              try {
                const data = JSON.parse(fs.readFileSync('$LATEST_SUMMARY', 'utf8'));
                console.log(data.coreWebVitals.CLS?.score || 0);
              } catch(e) { console.log('0'); }
            ")
          else
            PERF_SCORE="0"
            ACCESSIBILITY_SCORE="0"
            SEO_SCORE="0"
            BEST_PRACTICES_SCORE="0"
            LCP_SCORE="0"
            FID_SCORE="0"
            CLS_SCORE="0"
          fi
          
          echo "passed=$PASSED" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          echo "performance_score=$PERF_SCORE" >> $GITHUB_OUTPUT
          echo "accessibility_score=$ACCESSIBILITY_SCORE" >> $GITHUB_OUTPUT
          echo "seo_score=$SEO_SCORE" >> $GITHUB_OUTPUT
          echo "best_practices_score=$BEST_PRACTICES_SCORE" >> $GITHUB_OUTPUT
          echo "lcp_score=$LCP_SCORE" >> $GITHUB_OUTPUT
          echo "fid_score=$FID_SCORE" >> $GITHUB_OUTPUT
          echo "cls_score=$CLS_SCORE" >> $GITHUB_OUTPUT
          
          echo "Performance: $PERF_SCORE, Accessibility: $ACCESSIBILITY_SCORE, SEO: $SEO_SCORE"
          if [ "$FAILED" -gt "0" ]; then exit 1; fi

      - name: ğŸ§¹ Cleanup Servers
        if: always()
        run: |
          if [ -f backend-perf.pid ]; then
            kill $(cat backend-perf.pid) || true
            rm backend-perf.pid
          fi
          if [ -f frontend-perf.pid ]; then
            kill $(cat frontend-perf.pid) || true
            rm frontend-perf.pid
          fi

      - name: ğŸ“Š Upload Performance Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-test-results
          path: |
            frontend/lighthouse-reports/
            frontend/perf-output.log
            frontend/lighthouse-output.log
            frontend/test-results/
            backend-perf.log
            frontend-perf.log
          retention-days: 30

  # ========================================================================================
  # STAGE 8: END-TO-END TESTS
  # ========================================================================================
  e2e-tests:
    name: ğŸ­ End-to-End Tests
    runs-on: ubuntu-latest
    needs: [setup, lint, unit-tests, integration-tests, snapshot-tests]
    if: always() && github.event.inputs.skip_e2e_tests != 'true'
    outputs:
      tests-passed: ${{ steps.e2e-tests.outputs.passed }}
      tests-failed: ${{ steps.e2e-tests.outputs.failed }}
      tests-total: ${{ steps.e2e-tests.outputs.total }}
      test-duration: ${{ steps.e2e-tests.outputs.duration }}
    steps:
      - name: ğŸ” Checkout Repository
        uses: actions/checkout@v4

      - name: ğŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ğŸ“¦ Restore Dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.npm
            frontend/node_modules
            backend/node_modules
            ~/.cache/ms-playwright
          key: ${{ runner.os }}-node-${{ env.NODE_VERSION }}-${{ hashFiles('**/package-lock.json') }}

      - name: ğŸš€ Start Backend Server
        working-directory: backend
        run: |
          nohup npm start > ../backend-e2e.log 2>&1 & echo $! > ../backend-e2e.pid

      - name: ğŸŒ Start Frontend Server
        working-directory: frontend
        run: |
          nohup npm run preview > ../frontend-e2e.log 2>&1 & echo $! > ../frontend-e2e.pid

      - name: â³ Wait for Servers
        run: sleep 15

      - name: ğŸ­ Run E2E Tests
        id: e2e-tests
        working-directory: frontend
        run: |
          START_TIME=$(date +%s)
          npm run test:e2e:ci 2>&1 | tee e2e-output.log || true
          END_TIME=$(date +%s)
          DURATION=$((END_TIME - START_TIME))
          
          # Parse Playwright output
          PASSED=$(grep -oP '\K\d+(?=\s+passed)' e2e-output.log | tail -1 || echo "0")
          FAILED=$(grep -oP '\K\d+(?=\s+failed)' e2e-output.log | tail -1 || echo "0")
          TOTAL=$((PASSED + FAILED))
          
          echo "passed=$PASSED" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          echo "total=$TOTAL" >> $GITHUB_OUTPUT
          echo "duration=${DURATION}s" >> $GITHUB_OUTPUT
          
          echo "E2E Tests: $PASSED passed, $FAILED failed, ${DURATION}s duration"
          if [ "$FAILED" -gt "0" ]; then exit 1; fi

      - name: ğŸ§¹ Cleanup Servers
        if: always()
        run: |
          if [ -f backend-e2e.pid ]; then
            kill $(cat backend-e2e.pid) || true
            rm backend-e2e.pid
          fi
          if [ -f frontend-e2e.pid ]; then
            kill $(cat frontend-e2e.pid) || true
            rm frontend-e2e.pid
          fi

      - name: ğŸ“Š Upload E2E Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-test-results
          path: |
            frontend/e2e-output.log
            frontend/test-results/
            frontend/playwright-report/
            backend-e2e.log
            frontend-e2e.log
          retention-days: 30

  # ========================================================================================
  # STAGE 9: ENHANCED REPORTING & SLACK NOTIFICATIONS
  # ========================================================================================
  test-summary:
    name: ğŸ“‹ Test Summary & Enhanced Reporting
    runs-on: ubuntu-latest
    needs: [setup, lint, unit-tests, integration-tests, snapshot-tests, memory-leak-tests, performance-tests, e2e-tests]
    if: always()
    steps:
      - name: ğŸ” Checkout Repository
        uses: actions/checkout@v4

      - name: ğŸ“Š Download All Artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/

      - name: ğŸ“Š Generate Comprehensive Test Summary
        run: |
          echo "# ğŸ“‹ Comprehensive CI Pipeline Report" > test-summary.md
          echo "" >> test-summary.md
          echo "## ğŸ”„ Pipeline Overview" >> test-summary.md
          echo "- **Commit:** \`${{ github.sha }}\`" >> test-summary.md
          echo "- **Branch:** \`${{ github.ref_name }}\`" >> test-summary.md
          echo "- **Author:** ${{ github.actor }}" >> test-summary.md
          echo "- **Triggered by:** ${{ github.event_name }}" >> test-summary.md
          echo "- **Workflow:** ${{ github.workflow }}" >> test-summary.md
          echo "" >> test-summary.md
          
          # Determine overall status
          OVERALL_STATUS="âœ… SUCCESS"
          OVERALL_COLOR="good"
          
          if [[ "${{ needs.setup.result }}" == "failure" ]]; then
            OVERALL_STATUS="âŒ CRITICAL FAILURE"
            OVERALL_COLOR="danger"
          elif [[ "${{ needs.lint.result }}" == "failure" || "${{ needs.unit-tests.result }}" == "failure" || "${{ needs.integration-tests.result }}" == "failure" || "${{ needs.snapshot-tests.result }}" == "failure" || "${{ needs.memory-leak-tests.result }}" == "failure" || "${{ needs.performance-tests.result }}" == "failure" || "${{ needs.e2e-tests.result }}" == "failure" ]]; then
            OVERALL_STATUS="ğŸŸ¡ UNSTABLE"
            OVERALL_COLOR="warning"
          fi
          
          echo "## $OVERALL_STATUS" >> test-summary.md
          echo "" >> test-summary.md

      - name: ğŸ“¢ Send Enhanced Slack Notification
        if: always()
        run: |
          # Determine status and color
          if [[ "${{ needs.setup.result }}" == "failure" ]]; then
            STATUS="âŒ CI Pipeline FAILED"
            COLOR="danger"
          elif [[ "${{ needs.lint.result }}" == "failure" || "${{ needs.unit-tests.result }}" == "failure" || "${{ needs.integration-tests.result }}" == "failure" || "${{ needs.snapshot-tests.result }}" == "failure" || "${{ needs.memory-leak-tests.result }}" == "failure" || "${{ needs.performance-tests.result }}" == "failure" || "${{ needs.e2e-tests.result }}" == "failure" ]]; then
            STATUS="ğŸŸ¡ CI Pipeline UNSTABLE"
            COLOR="warning"
          else
            STATUS="âœ… CI Pipeline SUCCESS"
            COLOR="good"
          fi
          
          # Build the comprehensive message
          cat << EOF > slack_message.json
          {
            "text": "$STATUS",
            "attachments": [
              {
                "color": "$COLOR",
                "fields": [
                  {
                    "title": "ğŸ“¦ Setup & Dependencies",
                    "value": "${{ needs.setup.result == 'success' && 'âœ… Success' || 'âŒ Failed' }}",
                    "short": true
                  },
                  {
                    "title": "ğŸ” Code Quality & Linting",
                    "value": "${{ needs.lint.result == 'success' && format('âœ… Success\nFrontend: {0} warnings, {1} errors\nBackend: {2} warnings, {3} errors', needs.lint.outputs.frontend-warnings || '0', needs.lint.outputs.frontend-errors || '0', needs.lint.outputs.backend-warnings || '0', needs.lint.outputs.backend-errors || '0') || needs.lint.result == 'skipped' && 'â­ï¸ Skipped' || 'âŒ Failed' }}",
                    "short": true
                  },
                  {
                    "title": "ğŸ§ª Unit Tests",
                    "value": "${{ needs.unit-tests.result == 'success' && format('âœ… Success\nFrontend: {0}/{1} passed ({2}% coverage)\nBackend: {3}/{4} passed ({5}% coverage)', needs.unit-tests.outputs.frontend-tests-passed || '0', needs.unit-tests.outputs.frontend-tests-total || '0', needs.unit-tests.outputs.frontend-coverage || '0', needs.unit-tests.outputs.backend-tests-passed || '0', needs.unit-tests.outputs.backend-tests-total || '0', needs.unit-tests.outputs.backend-coverage || '0') || needs.unit-tests.result == 'skipped' && 'â­ï¸ Skipped' || 'âŒ Failed' }}",
                    "short": true
                  },
                  {
                    "title": "ğŸ”— Integration Tests",
                    "value": "${{ needs.integration-tests.result == 'success' && format('âœ… Success\nFrontend: {0}/{1} passed\nBackend: {2}/{3} passed', needs.integration-tests.outputs.frontend-passed || '0', needs.integration-tests.outputs.frontend-total || '0', needs.integration-tests.outputs.backend-passed || '0', needs.integration-tests.outputs.backend-total || '0') || needs.integration-tests.result == 'skipped' && 'â­ï¸ Skipped' || 'âŒ Failed' }}",
                    "short": true
                  },
                  {
                    "title": "ğŸ“¸ Snapshot Tests",
                    "value": "${{ needs.snapshot-tests.result == 'success' && format('âœ… Success\nFrontend: {0} passed\nBackend: {1} passed', needs.snapshot-tests.outputs.frontend-passed || '0', needs.snapshot-tests.outputs.backend-passed || '0') || needs.snapshot-tests.result == 'skipped' && 'â­ï¸ Skipped' || 'âŒ Failed' }}",
                    "short": true
                  },
                  {
                    "title": "ğŸ§  Memory Leak Tests",
                    "value": "${{ needs.memory-leak-tests.result == 'success' && format('âœ… Success\n{0}/{1} passed\n{2} leaks detected\nMemory usage: {3}', needs.memory-leak-tests.outputs.tests-passed || '0', needs.memory-leak-tests.outputs.tests-passed + needs.memory-leak-tests.outputs.tests-failed || '0', needs.memory-leak-tests.outputs.leaks-detected || '0', needs.memory-leak-tests.outputs.memory-usage || 'N/A') || needs.memory-leak-tests.result == 'skipped' && 'â­ï¸ Skipped' || 'âŒ Failed' }}",
                    "short": true
                  },
                  {
                    "title": "âš¡ Performance Tests",
                    "value": "${{ needs.performance-tests.result == 'success' && format('âœ… Success\n{0}/{1} Playwright tests passed\nPerformance: {2}%\nAccessibility: {3}%\nSEO: {4}%\nBest Practices: {5}%\nCore Web Vitals:\nâ€¢ LCP: {6}%\nâ€¢ FID: {7}%\nâ€¢ CLS: {8}%', needs.performance-tests.outputs.tests-passed || '0', needs.performance-tests.outputs.tests-passed + needs.performance-tests.outputs.tests-failed || '0', needs.performance-tests.outputs.performance-score || '0', needs.performance-tests.outputs.accessibility-score || '0', needs.performance-tests.outputs.seo-score || '0', needs.performance-tests.outputs.best-practices-score || '0', needs.performance-tests.outputs.lcp-score || '0', needs.performance-tests.outputs.fid-score || '0', needs.performance-tests.outputs.cls-score || '0') || needs.performance-tests.result == 'skipped' && 'â­ï¸ Skipped' || 'âŒ Failed' }}",
                    "short": true
                  },
                  {
                    "title": "ğŸ­ End-to-End Tests",
                    "value": "${{ needs.e2e-tests.result == 'success' && format('âœ… Success\n{0}/{1} tests passed\nDuration: {2}', needs.e2e-tests.outputs.tests-passed || '0', needs.e2e-tests.outputs.tests-total || '0', needs.e2e-tests.outputs.test-duration || 'N/A') || needs.e2e-tests.result == 'skipped' && 'â­ï¸ Skipped' || 'âŒ Failed' }}",
                    "short": true
                  }
                ],
                "footer": "GitHub Actions CI/CD",
                "footer_icon": "https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png",
                "ts": $(date +%s)
              },
              {
                "color": "$COLOR",
                "fields": [
                  {
                    "title": "ğŸ“ Details",
                    "value": "â€¢ **Commit:** \`${{ github.sha }}\`\nâ€¢ **Branch:** \`${{ github.ref_name }}\`\nâ€¢ **Author:** ${{ github.actor }}\nâ€¢ **Workflow:** <${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|View Details>",
                    "short": false
                  }
                ]
              }
            ]
          }
          EOF
          
          # Send to Slack
          curl -X POST -H 'Content-type: application/json' \
               --data @slack_message.json \
               ${{ env.SLACK_WEBHOOK_URL }}

      - name: ğŸ“Š Upload Enhanced Test Summary
        uses: actions/upload-artifact@v4
        with:
          name: comprehensive-test-summary
          path: |
            test-summary.md
            slack_message.json
          retention-days: 30 
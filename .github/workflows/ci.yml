name: 🔄 Continuous Integration

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:
    inputs:
      skip_lint:
        description: 'Skip Linting'
        required: false
        default: false
        type: boolean
      skip_unit_tests:
        description: 'Skip Unit Tests'
        required: false
        default: false
        type: boolean
      skip_snapshot_tests:
        description: 'Skip Snapshot Tests'
        required: false
        default: false
        type: boolean
      skip_memory_leak_tests:
        description: 'Skip Memory Leak Tests'
        required: false
        default: false
        type: boolean
      skip_performance_tests:
        description: 'Skip Performance Tests'
        required: false
        default: false
        type: boolean
      skip_e2e_tests:
        description: 'Skip End-to-End Tests'
        required: false
        default: false
        type: boolean
      skip_integration_tests:
        description: 'Skip Integration Tests'
        required: false
        default: false
        type: boolean

env:
  NODE_VERSION: '18'
  SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

jobs:
  # ========================================================================================
  # STAGE 1: SETUP & DEPENDENCIES
  # ========================================================================================
  setup:
    name: 📦 Setup & Install Dependencies
    runs-on: ubuntu-latest
    outputs:
      cache-hit: ${{ steps.cache-deps.outputs.cache-hit }}
    steps:
      - name: 🔍 Checkout Repository
        uses: actions/checkout@v4

      - name: 🔧 Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: 📦 Cache Dependencies
        id: cache-deps
        uses: actions/cache@v4
        with:
          path: |
            ~/.npm
            frontend/node_modules
            backend/node_modules
            ~/.cache/ms-playwright
          key: ${{ runner.os }}-node-${{ env.NODE_VERSION }}-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-node-${{ env.NODE_VERSION }}-

      - name: 🔨 Install Root Dependencies
        if: steps.cache-deps.outputs.cache-hit != 'true'
        run: npm ci

      - name: 🔨 Install Frontend Dependencies
        if: steps.cache-deps.outputs.cache-hit != 'true'
        working-directory: frontend
        run: |
          npm ci
          npx playwright install

      - name: 🔨 Install Backend Dependencies
        if: steps.cache-deps.outputs.cache-hit != 'true'
        working-directory: backend
        run: npm ci

  # ========================================================================================
  # STAGE 2: LINTING & CODE QUALITY
  # ========================================================================================
  lint:
    name: 🔍 Lint & Code Quality
    runs-on: ubuntu-latest
    needs: setup
    if: github.event.inputs.skip_lint != 'true'
    outputs:
      frontend-warnings: ${{ steps.lint-frontend.outputs.warnings }}
      frontend-errors: ${{ steps.lint-frontend.outputs.errors }}
      backend-warnings: ${{ steps.lint-backend.outputs.warnings }}
      backend-errors: ${{ steps.lint-backend.outputs.errors }}
    steps:
      - name: 🔍 Checkout Repository
        uses: actions/checkout@v4

      - name: 🔧 Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: 📦 Restore Dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.npm
            frontend/node_modules
            backend/node_modules
          key: ${{ runner.os }}-node-${{ env.NODE_VERSION }}-${{ hashFiles('**/package-lock.json') }}

      - name: 🔍 Run Frontend ESLint
        id: lint-frontend
        working-directory: frontend
        run: |
          npm run lint:check 2>&1 | tee eslint-output.log || true
          WARNINGS=$(grep -c "warning" eslint-output.log || echo "0")
          ERRORS=$(grep -c "error" eslint-output.log || echo "0")
          echo "warnings=$WARNINGS" >> $GITHUB_OUTPUT
          echo "errors=$ERRORS" >> $GITHUB_OUTPUT
          echo "Frontend: $WARNINGS warnings, $ERRORS errors"
          if [ "$ERRORS" -gt "0" ]; then exit 1; fi

      - name: 🔍 Run Backend ESLint
        id: lint-backend
        working-directory: backend
        run: |
          npm run lint:check 2>&1 | tee eslint-output.log || true
          WARNINGS=$(grep -c "warning" eslint-output.log || echo "0")
          ERRORS=$(grep -c "error" eslint-output.log || echo "0")
          echo "warnings=$WARNINGS" >> $GITHUB_OUTPUT
          echo "errors=$ERRORS" >> $GITHUB_OUTPUT
          echo "Backend: $WARNINGS warnings, $ERRORS errors"
          if [ "$ERRORS" -gt "0" ]; then exit 1; fi

      - name: 📊 Upload Lint Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: lint-results
          path: |
            frontend/eslint-output.log
            backend/eslint-output.log
          retention-days: 30

  # ========================================================================================
  # STAGE 3: UNIT TESTS
  # ========================================================================================
  unit-tests:
    name: 🧪 Unit Tests
    runs-on: ubuntu-latest
    needs: [setup, lint]
    if: always() && github.event.inputs.skip_unit_tests != 'true'
    outputs:
      frontend-coverage: ${{ steps.test-frontend.outputs.coverage }}
      frontend-tests-passed: ${{ steps.test-frontend.outputs.passed }}
      frontend-tests-failed: ${{ steps.test-frontend.outputs.failed }}
      frontend-tests-total: ${{ steps.test-frontend.outputs.total }}
      backend-coverage: ${{ steps.test-backend.outputs.coverage }}
      backend-tests-passed: ${{ steps.test-backend.outputs.passed }}
      backend-tests-failed: ${{ steps.test-backend.outputs.failed }}
      backend-tests-total: ${{ steps.test-backend.outputs.total }}
    steps:
      - name: 🔍 Checkout Repository
        uses: actions/checkout@v4

      - name: 🔧 Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: 📦 Restore Dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.npm
            frontend/node_modules
            backend/node_modules
          key: ${{ runner.os }}-node-${{ env.NODE_VERSION }}-${{ hashFiles('**/package-lock.json') }}

      - name: 🧪 Run Frontend Unit Tests
        id: test-frontend
        working-directory: frontend
        run: |
          npm run test:ci 2>&1 | tee test-output.log
          
          # Parse Jest output for test counts
          PASSED=$(grep -oP 'Tests:\s+\K\d+(?=\s+passed)' test-output.log || echo "0")
          FAILED=$(grep -oP 'Tests:\s+\d+\s+passed,\s+\K\d+(?=\s+failed)' test-output.log || echo "0")
          TOTAL=$(grep -oP 'Tests:\s+\K\d+(?=\s+total)' test-output.log || echo "0")
          
          # Parse coverage
          if [ -f "coverage/coverage-summary.json" ]; then
            COVERAGE=$(node -e "
              const fs = require('fs');
              try {
                const coverage = JSON.parse(fs.readFileSync('coverage/coverage-summary.json', 'utf8'));
                console.log(Math.round(coverage.total.lines.pct));
              } catch(e) {
                console.log('0');
              }
            ")
          else
            COVERAGE="0"
          fi
          
          echo "passed=$PASSED" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          echo "total=$TOTAL" >> $GITHUB_OUTPUT
          echo "coverage=$COVERAGE" >> $GITHUB_OUTPUT
          
          echo "Frontend Tests: $PASSED passed, $FAILED failed, $TOTAL total, $COVERAGE% coverage"

      - name: 🧪 Run Backend Unit Tests
        id: test-backend
        working-directory: backend
        run: |
          npm run test:coverage 2>&1 | tee test-output.log
          
          # Parse Jest output for test counts
          PASSED=$(grep -oP 'Tests:\s+\K\d+(?=\s+passed)' test-output.log || echo "0")
          FAILED=$(grep -oP 'Tests:\s+\d+\s+passed,\s+\K\d+(?=\s+failed)' test-output.log || echo "0")
          TOTAL=$(grep -oP 'Tests:\s+\K\d+(?=\s+total)' test-output.log || echo "0")
          
          # Parse coverage
          if [ -f "coverage/coverage-summary.json" ]; then
            COVERAGE=$(node -e "
              const fs = require('fs');
              try {
                const coverage = JSON.parse(fs.readFileSync('coverage/coverage-summary.json', 'utf8'));
                console.log(Math.round(coverage.total.lines.pct));
              } catch(e) {
                console.log('0');
              }
            ")
          else
            COVERAGE="0"
          fi
          
          echo "passed=$PASSED" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          echo "total=$TOTAL" >> $GITHUB_OUTPUT
          echo "coverage=$COVERAGE" >> $GITHUB_OUTPUT
          
          echo "Backend Tests: $PASSED passed, $FAILED failed, $TOTAL total, $COVERAGE% coverage"

      - name: 📊 Upload Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: unit-test-results
          path: |
            frontend/coverage/
            backend/coverage/
            frontend/test-output.log
            backend/test-output.log
          retention-days: 30

  # ========================================================================================
  # STAGE 4: INTEGRATION TESTS
  # ========================================================================================
  integration-tests:
    name: 🔗 Integration Tests
    runs-on: ubuntu-latest
    needs: [setup, lint, unit-tests]
    if: always() && github.event.inputs.skip_integration_tests != 'true'
    outputs:
      frontend-passed: ${{ steps.integration-frontend.outputs.passed }}
      frontend-failed: ${{ steps.integration-frontend.outputs.failed }}
      frontend-total: ${{ steps.integration-frontend.outputs.total }}
      backend-passed: ${{ steps.integration-backend.outputs.passed }}
      backend-failed: ${{ steps.integration-backend.outputs.failed }}
      backend-total: ${{ steps.integration-backend.outputs.total }}
    steps:
      - name: 🔍 Checkout Repository
        uses: actions/checkout@v4

      - name: 🔧 Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: 📦 Restore Dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.npm
            frontend/node_modules
            backend/node_modules
            ~/.cache/ms-playwright
          key: ${{ runner.os }}-node-${{ env.NODE_VERSION }}-${{ hashFiles('**/package-lock.json') }}

      - name: 🔗 Run Frontend Integration Tests
        id: integration-frontend
        working-directory: frontend
        run: |
          npm run test:integration:ci 2>&1 | tee integration-output.log || true
          
          # Parse Playwright output
          PASSED=$(grep -oP '\K\d+(?=\s+passed)' integration-output.log | tail -1 || echo "0")
          FAILED=$(grep -oP '\K\d+(?=\s+failed)' integration-output.log | tail -1 || echo "0")
          TOTAL=$((PASSED + FAILED))
          
          echo "passed=$PASSED" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          echo "total=$TOTAL" >> $GITHUB_OUTPUT
          
          echo "Frontend Integration: $PASSED passed, $FAILED failed"
          if [ "$FAILED" -gt "0" ]; then exit 1; fi

      - name: 🔗 Run Backend Integration Tests
        id: integration-backend
        working-directory: backend
        run: |
          npm run test:integration:ci 2>&1 | tee integration-output.log || true
          
          # Parse Jest output
          PASSED=$(grep -oP 'Tests:\s+\K\d+(?=\s+passed)' integration-output.log || echo "0")
          FAILED=$(grep -oP 'Tests:\s+\d+\s+passed,\s+\K\d+(?=\s+failed)' integration-output.log || echo "0")
          TOTAL=$(grep -oP 'Tests:\s+\K\d+(?=\s+total)' integration-output.log || echo "0")
          
          echo "passed=$PASSED" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          echo "total=$TOTAL" >> $GITHUB_OUTPUT
          
          echo "Backend Integration: $PASSED passed, $FAILED failed"
          if [ "$FAILED" -gt "0" ]; then exit 1; fi

      - name: 📊 Upload Integration Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: integration-test-results
          path: |
            frontend/integration-output.log
            backend/integration-output.log
            frontend/test-results/
            frontend/playwright-report/
          retention-days: 30

  # ========================================================================================
  # STAGE 5: SNAPSHOT TESTS
  # ========================================================================================
  snapshot-tests:
    name: 📸 Snapshot Tests
    runs-on: ubuntu-latest
    needs: [setup, lint, integration-tests]
    if: always() && github.event.inputs.skip_snapshot_tests != 'true'
    outputs:
      frontend-passed: ${{ steps.snapshot-frontend.outputs.passed }}
      frontend-failed: ${{ steps.snapshot-frontend.outputs.failed }}
      backend-passed: ${{ steps.snapshot-backend.outputs.passed }}
      backend-failed: ${{ steps.snapshot-backend.outputs.failed }}
    steps:
      - name: 🔍 Checkout Repository
        uses: actions/checkout@v4

      - name: 🔧 Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: 📦 Restore Dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.npm
            frontend/node_modules
            backend/node_modules
          key: ${{ runner.os }}-node-${{ env.NODE_VERSION }}-${{ hashFiles('**/package-lock.json') }}

      - name: 📸 Run Frontend Snapshot Tests
        id: snapshot-frontend
        working-directory: frontend
        run: |
          npm run test:snapshot:ci 2>&1 | tee snapshot-output.log || true
          
          PASSED=$(grep -oP 'Tests:\s+\K\d+(?=\s+passed)' snapshot-output.log || echo "0")
          FAILED=$(grep -oP 'Tests:\s+\d+\s+passed,\s+\K\d+(?=\s+failed)' snapshot-output.log || echo "0")
          
          echo "passed=$PASSED" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          
          echo "Frontend Snapshots: $PASSED passed, $FAILED failed"
          if [ "$FAILED" -gt "0" ]; then exit 1; fi

      - name: 📸 Run Backend Snapshot Tests
        id: snapshot-backend
        working-directory: backend
        run: |
          npm run test:snapshot:ci 2>&1 | tee snapshot-output.log || true
          
          PASSED=$(grep -oP 'Tests:\s+\K\d+(?=\s+passed)' snapshot-output.log || echo "0")
          FAILED=$(grep -oP 'Tests:\s+\d+\s+passed,\s+\K\d+(?=\s+failed)' snapshot-output.log || echo "0")
          
          echo "passed=$PASSED" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          
          echo "Backend Snapshots: $PASSED passed, $FAILED failed"
          if [ "$FAILED" -gt "0" ]; then exit 1; fi

  # ========================================================================================
  # STAGE 6: MEMORY LEAK TESTS
  # ========================================================================================
  memory-leak-tests:
    name: 🧠 Memory Leak Tests
    runs-on: ubuntu-latest
    needs: [setup, lint, unit-tests, integration-tests]
    if: always() && github.event.inputs.skip_memory_leak_tests != 'true'
    outputs:
      tests-passed: ${{ steps.memory-tests.outputs.passed }}
      tests-failed: ${{ steps.memory-tests.outputs.failed }}
      memory-usage: ${{ steps.memory-tests.outputs.memory_usage }}
      leaks-detected: ${{ steps.memory-tests.outputs.leaks_detected }}
    steps:
      - name: 🔍 Checkout Repository
        uses: actions/checkout@v4

      - name: 🔧 Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: 📦 Restore Dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.npm
            frontend/node_modules
            backend/node_modules
            ~/.cache/ms-playwright
          key: ${{ runner.os }}-node-${{ env.NODE_VERSION }}-${{ hashFiles('**/package-lock.json') }}

      - name: 🚀 Start Backend Server
        working-directory: backend
        run: |
          nohup npm start > ../backend-memory.log 2>&1 & echo $! > ../backend-memory.pid

      - name: 🌐 Start Frontend Server
        working-directory: frontend
        run: |
          nohup npm run preview > ../frontend-memory.log 2>&1 & echo $! > ../frontend-memory.pid

      - name: ⏳ Wait for Servers
        run: sleep 15

      - name: 🧠 Run Memory Leak Tests
        id: memory-tests
        working-directory: frontend
        run: |
          npm run test:memory-leaks:ci 2>&1 | tee memory-output.log || true
          
          # Parse memory test results
          PASSED=$(grep -oP '\K\d+(?=\s+passed)' memory-output.log | tail -1 || echo "0")
          FAILED=$(grep -oP '\K\d+(?=\s+failed)' memory-output.log | tail -1 || echo "0")
          
          # Extract memory usage info (if available in logs)
          MEMORY_USAGE=$(grep -oP 'Memory usage:\s+\K[\d.]+\s*MB' memory-output.log | tail -1 || echo "N/A")
          LEAKS_DETECTED=$(grep -c "Memory leak detected" memory-output.log || echo "0")
          
          echo "passed=$PASSED" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          echo "memory_usage=$MEMORY_USAGE" >> $GITHUB_OUTPUT
          echo "leaks_detected=$LEAKS_DETECTED" >> $GITHUB_OUTPUT
          
          echo "Memory Tests: $PASSED passed, $FAILED failed, $LEAKS_DETECTED leaks detected"
          if [ "$FAILED" -gt "0" ] || [ "$LEAKS_DETECTED" -gt "0" ]; then exit 1; fi

      - name: 🧹 Cleanup Servers
        if: always()
        run: |
          if [ -f backend-memory.pid ]; then
            kill $(cat backend-memory.pid) || true
            rm backend-memory.pid
          fi
          if [ -f frontend-memory.pid ]; then
            kill $(cat frontend-memory.pid) || true
            rm frontend-memory.pid
          fi

      - name: 📊 Upload Memory Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: memory-leak-test-results
          path: |
            frontend/memory-output.log
            frontend/test-results/
            backend-memory.log
            frontend-memory.log
          retention-days: 30

  # ========================================================================================
  # STAGE 7: PERFORMANCE TESTS
  # ========================================================================================
  performance-tests:
    name: ⚡ Performance Tests
    runs-on: ubuntu-latest
    needs: [setup, lint, unit-tests, integration-tests]
    if: always() && github.event.inputs.skip_performance_tests != 'true'
    outputs:
      performance-score: ${{ steps.perf-tests.outputs.performance_score }}
      accessibility-score: ${{ steps.perf-tests.outputs.accessibility_score }}
      seo-score: ${{ steps.perf-tests.outputs.seo_score }}
      best-practices-score: ${{ steps.perf-tests.outputs.best_practices_score }}
      lcp-score: ${{ steps.perf-tests.outputs.lcp_score }}
      fid-score: ${{ steps.perf-tests.outputs.fid_score }}
      cls-score: ${{ steps.perf-tests.outputs.cls_score }}
      tests-passed: ${{ steps.perf-tests.outputs.passed }}
      tests-failed: ${{ steps.perf-tests.outputs.failed }}
    steps:
      - name: 🔍 Checkout Repository
        uses: actions/checkout@v4

      - name: 🔧 Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: 📦 Restore Dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.npm
            frontend/node_modules
            backend/node_modules
            ~/.cache/ms-playwright
          key: ${{ runner.os }}-node-${{ env.NODE_VERSION }}-${{ hashFiles('**/package-lock.json') }}

      - name: 🚀 Start Backend Server
        working-directory: backend
        run: |
          nohup npm start > ../backend-perf.log 2>&1 & echo $! > ../backend-perf.pid

      - name: 🌐 Start Frontend Server
        working-directory: frontend
        run: |
          nohup npm run preview > ../frontend-perf.log 2>&1 & echo $! > ../frontend-perf.pid

      - name: ⏳ Wait for Servers
        run: sleep 15

      - name: 🎭 Run Performance Tests
        working-directory: frontend
        run: |
          npm run test:perf:ci 2>&1 | tee perf-output.log || true

      - name: 🔍 Run Lighthouse Tests
        id: perf-tests
        working-directory: frontend
        run: |
          npm run test:lighthouse:ci 2>&1 | tee lighthouse-output.log || true
          
          # Parse Playwright test results
          PASSED=$(grep -oP '\K\d+(?=\s+passed)' perf-output.log | tail -1 || echo "0")
          FAILED=$(grep -oP '\K\d+(?=\s+failed)' perf-output.log | tail -1 || echo "0")
          
          # Parse Lighthouse scores from latest summary file
          if [ -f "lighthouse-reports/"*"-summary.json" ]; then
            LATEST_SUMMARY=$(ls -t lighthouse-reports/*-summary.json | head -1)
            PERF_SCORE=$(node -e "
              const fs = require('fs');
              try {
                const data = JSON.parse(fs.readFileSync('$LATEST_SUMMARY', 'utf8'));
                console.log(data.scores.performance || 0);
              } catch(e) { console.log('0'); }
            ")
            ACCESSIBILITY_SCORE=$(node -e "
              const fs = require('fs');
              try {
                const data = JSON.parse(fs.readFileSync('$LATEST_SUMMARY', 'utf8'));
                console.log(data.scores.accessibility || 0);
              } catch(e) { console.log('0'); }
            ")
            SEO_SCORE=$(node -e "
              const fs = require('fs');
              try {
                const data = JSON.parse(fs.readFileSync('$LATEST_SUMMARY', 'utf8'));
                console.log(data.scores.seo || 0);
              } catch(e) { console.log('0'); }
            ")
            BEST_PRACTICES_SCORE=$(node -e "
              const fs = require('fs');
              try {
                const data = JSON.parse(fs.readFileSync('$LATEST_SUMMARY', 'utf8'));
                console.log(data.scores['best-practices'] || 0);
              } catch(e) { console.log('0'); }
            ")
            LCP_SCORE=$(node -e "
              const fs = require('fs');
              try {
                const data = JSON.parse(fs.readFileSync('$LATEST_SUMMARY', 'utf8'));
                console.log(data.coreWebVitals.LCP?.score || 0);
              } catch(e) { console.log('0'); }
            ")
            FID_SCORE=$(node -e "
              const fs = require('fs');
              try {
                const data = JSON.parse(fs.readFileSync('$LATEST_SUMMARY', 'utf8'));
                console.log(data.coreWebVitals.FID?.score || 0);
              } catch(e) { console.log('0'); }
            ")
            CLS_SCORE=$(node -e "
              const fs = require('fs');
              try {
                const data = JSON.parse(fs.readFileSync('$LATEST_SUMMARY', 'utf8'));
                console.log(data.coreWebVitals.CLS?.score || 0);
              } catch(e) { console.log('0'); }
            ")
          else
            PERF_SCORE="0"
            ACCESSIBILITY_SCORE="0"
            SEO_SCORE="0"
            BEST_PRACTICES_SCORE="0"
            LCP_SCORE="0"
            FID_SCORE="0"
            CLS_SCORE="0"
          fi
          
          echo "passed=$PASSED" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          echo "performance_score=$PERF_SCORE" >> $GITHUB_OUTPUT
          echo "accessibility_score=$ACCESSIBILITY_SCORE" >> $GITHUB_OUTPUT
          echo "seo_score=$SEO_SCORE" >> $GITHUB_OUTPUT
          echo "best_practices_score=$BEST_PRACTICES_SCORE" >> $GITHUB_OUTPUT
          echo "lcp_score=$LCP_SCORE" >> $GITHUB_OUTPUT
          echo "fid_score=$FID_SCORE" >> $GITHUB_OUTPUT
          echo "cls_score=$CLS_SCORE" >> $GITHUB_OUTPUT
          
          echo "Performance: $PERF_SCORE, Accessibility: $ACCESSIBILITY_SCORE, SEO: $SEO_SCORE"
          if [ "$FAILED" -gt "0" ]; then exit 1; fi

      - name: 🧹 Cleanup Servers
        if: always()
        run: |
          if [ -f backend-perf.pid ]; then
            kill $(cat backend-perf.pid) || true
            rm backend-perf.pid
          fi
          if [ -f frontend-perf.pid ]; then
            kill $(cat frontend-perf.pid) || true
            rm frontend-perf.pid
          fi

      - name: 📊 Upload Performance Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-test-results
          path: |
            frontend/lighthouse-reports/
            frontend/perf-output.log
            frontend/lighthouse-output.log
            frontend/test-results/
            backend-perf.log
            frontend-perf.log
          retention-days: 30

  # ========================================================================================
  # STAGE 8: END-TO-END TESTS
  # ========================================================================================
  e2e-tests:
    name: 🎭 End-to-End Tests
    runs-on: ubuntu-latest
    needs: [setup, lint, unit-tests, integration-tests, snapshot-tests]
    if: always() && github.event.inputs.skip_e2e_tests != 'true'
    outputs:
      tests-passed: ${{ steps.e2e-tests.outputs.passed }}
      tests-failed: ${{ steps.e2e-tests.outputs.failed }}
      tests-total: ${{ steps.e2e-tests.outputs.total }}
      test-duration: ${{ steps.e2e-tests.outputs.duration }}
    steps:
      - name: 🔍 Checkout Repository
        uses: actions/checkout@v4

      - name: 🔧 Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: 📦 Restore Dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.npm
            frontend/node_modules
            backend/node_modules
            ~/.cache/ms-playwright
          key: ${{ runner.os }}-node-${{ env.NODE_VERSION }}-${{ hashFiles('**/package-lock.json') }}

      - name: 🚀 Start Backend Server
        working-directory: backend
        run: |
          nohup npm start > ../backend-e2e.log 2>&1 & echo $! > ../backend-e2e.pid

      - name: 🌐 Start Frontend Server
        working-directory: frontend
        run: |
          nohup npm run preview > ../frontend-e2e.log 2>&1 & echo $! > ../frontend-e2e.pid

      - name: ⏳ Wait for Servers
        run: sleep 15

      - name: 🎭 Run E2E Tests
        id: e2e-tests
        working-directory: frontend
        run: |
          START_TIME=$(date +%s)
          npm run test:e2e:ci 2>&1 | tee e2e-output.log || true
          END_TIME=$(date +%s)
          DURATION=$((END_TIME - START_TIME))
          
          # Parse Playwright output
          PASSED=$(grep -oP '\K\d+(?=\s+passed)' e2e-output.log | tail -1 || echo "0")
          FAILED=$(grep -oP '\K\d+(?=\s+failed)' e2e-output.log | tail -1 || echo "0")
          TOTAL=$((PASSED + FAILED))
          
          echo "passed=$PASSED" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          echo "total=$TOTAL" >> $GITHUB_OUTPUT
          echo "duration=${DURATION}s" >> $GITHUB_OUTPUT
          
          echo "E2E Tests: $PASSED passed, $FAILED failed, ${DURATION}s duration"
          if [ "$FAILED" -gt "0" ]; then exit 1; fi

      - name: 🧹 Cleanup Servers
        if: always()
        run: |
          if [ -f backend-e2e.pid ]; then
            kill $(cat backend-e2e.pid) || true
            rm backend-e2e.pid
          fi
          if [ -f frontend-e2e.pid ]; then
            kill $(cat frontend-e2e.pid) || true
            rm frontend-e2e.pid
          fi

      - name: 📊 Upload E2E Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-test-results
          path: |
            frontend/e2e-output.log
            frontend/test-results/
            frontend/playwright-report/
            backend-e2e.log
            frontend-e2e.log
          retention-days: 30

  # ========================================================================================
  # STAGE 9: ENHANCED REPORTING & SLACK NOTIFICATIONS
  # ========================================================================================
  test-summary:
    name: 📋 Test Summary & Enhanced Reporting
    runs-on: ubuntu-latest
    needs: [setup, lint, unit-tests, integration-tests, snapshot-tests, memory-leak-tests, performance-tests, e2e-tests]
    if: always()
    steps:
      - name: 🔍 Checkout Repository
        uses: actions/checkout@v4

      - name: 📊 Download All Artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/

      - name: 📊 Generate Comprehensive Test Summary
        run: |
          echo "# 📋 Comprehensive CI Pipeline Report" > test-summary.md
          echo "" >> test-summary.md
          echo "## 🔄 Pipeline Overview" >> test-summary.md
          echo "- **Commit:** \`${{ github.sha }}\`" >> test-summary.md
          echo "- **Branch:** \`${{ github.ref_name }}\`" >> test-summary.md
          echo "- **Author:** ${{ github.actor }}" >> test-summary.md
          echo "- **Triggered by:** ${{ github.event_name }}" >> test-summary.md
          echo "- **Workflow:** ${{ github.workflow }}" >> test-summary.md
          echo "" >> test-summary.md
          
          # Determine overall status
          OVERALL_STATUS="✅ SUCCESS"
          OVERALL_COLOR="good"
          
          if [[ "${{ needs.setup.result }}" == "failure" ]]; then
            OVERALL_STATUS="❌ CRITICAL FAILURE"
            OVERALL_COLOR="danger"
          elif [[ "${{ needs.lint.result }}" == "failure" || "${{ needs.unit-tests.result }}" == "failure" || "${{ needs.integration-tests.result }}" == "failure" || "${{ needs.snapshot-tests.result }}" == "failure" || "${{ needs.memory-leak-tests.result }}" == "failure" || "${{ needs.performance-tests.result }}" == "failure" || "${{ needs.e2e-tests.result }}" == "failure" ]]; then
            OVERALL_STATUS="🟡 UNSTABLE"
            OVERALL_COLOR="warning"
          fi
          
          echo "## $OVERALL_STATUS" >> test-summary.md
          echo "" >> test-summary.md

      - name: 📢 Send Enhanced Slack Notification
        if: always()
        run: |
          # Determine status and color
          if [[ "${{ needs.setup.result }}" == "failure" ]]; then
            STATUS="❌ CI Pipeline FAILED"
            COLOR="danger"
          elif [[ "${{ needs.lint.result }}" == "failure" || "${{ needs.unit-tests.result }}" == "failure" || "${{ needs.integration-tests.result }}" == "failure" || "${{ needs.snapshot-tests.result }}" == "failure" || "${{ needs.memory-leak-tests.result }}" == "failure" || "${{ needs.performance-tests.result }}" == "failure" || "${{ needs.e2e-tests.result }}" == "failure" ]]; then
            STATUS="🟡 CI Pipeline UNSTABLE"
            COLOR="warning"
          else
            STATUS="✅ CI Pipeline SUCCESS"
            COLOR="good"
          fi
          
          # Build individual field values
          
          # Setup field
          if [[ "${{ needs.setup.result }}" == "success" ]]; then
            SETUP_VALUE="✅ Success"
          else
            SETUP_VALUE="❌ Failed"
          fi
          
          # Lint field
          if [[ "${{ needs.lint.result }}" == "success" ]]; then
            LINT_VALUE="✅ Success\\nFrontend: ${{ needs.lint.outputs.frontend-warnings || '0' }} warnings, ${{ needs.lint.outputs.frontend-errors || '0' }} errors\\nBackend: ${{ needs.lint.outputs.backend-warnings || '0' }} warnings, ${{ needs.lint.outputs.backend-errors || '0' }} errors"
          elif [[ "${{ needs.lint.result }}" == "skipped" ]]; then
            LINT_VALUE="⏭️ Skipped"
          else
            LINT_VALUE="❌ Failed"
          fi
          
          # Unit Tests field
          if [[ "${{ needs.unit-tests.result }}" == "success" ]]; then
            UNIT_VALUE="✅ Success\\nFrontend: ${{ needs.unit-tests.outputs.frontend-tests-passed || '0' }}/${{ needs.unit-tests.outputs.frontend-tests-total || '0' }} passed (${{ needs.unit-tests.outputs.frontend-coverage || '0' }}% coverage)\\nBackend: ${{ needs.unit-tests.outputs.backend-tests-passed || '0' }}/${{ needs.unit-tests.outputs.backend-tests-total || '0' }} passed (${{ needs.unit-tests.outputs.backend-coverage || '0' }}% coverage)"
          elif [[ "${{ needs.unit-tests.result }}" == "skipped" ]]; then
            UNIT_VALUE="⏭️ Skipped"
          else
            UNIT_VALUE="❌ Failed"
          fi
          
          # Integration Tests field
          if [[ "${{ needs.integration-tests.result }}" == "success" ]]; then
            INTEGRATION_VALUE="✅ Success\\nFrontend: ${{ needs.integration-tests.outputs.frontend-passed || '0' }}/${{ needs.integration-tests.outputs.frontend-total || '0' }} passed\\nBackend: ${{ needs.integration-tests.outputs.backend-passed || '0' }}/${{ needs.integration-tests.outputs.backend-total || '0' }} passed"
          elif [[ "${{ needs.integration-tests.result }}" == "skipped" ]]; then
            INTEGRATION_VALUE="⏭️ Skipped"
          else
            INTEGRATION_VALUE="❌ Failed"
          fi
          
          # Snapshot Tests field
          if [[ "${{ needs.snapshot-tests.result }}" == "success" ]]; then
            SNAPSHOT_VALUE="✅ Success\\nFrontend: ${{ needs.snapshot-tests.outputs.frontend-passed || '0' }} passed\\nBackend: ${{ needs.snapshot-tests.outputs.backend-passed || '0' }} passed"
          elif [[ "${{ needs.snapshot-tests.result }}" == "skipped" ]]; then
            SNAPSHOT_VALUE="⏭️ Skipped"
          else
            SNAPSHOT_VALUE="❌ Failed"
          fi
          
          # Memory Leak Tests field
          if [[ "${{ needs.memory-leak-tests.result }}" == "success" ]]; then
            MEMORY_PASSED="${{ needs.memory-leak-tests.outputs.tests-passed || '0' }}"
            MEMORY_FAILED="${{ needs.memory-leak-tests.outputs.tests-failed || '0' }}"
            MEMORY_TOTAL=$((MEMORY_PASSED + MEMORY_FAILED))
            MEMORY_VALUE="✅ Success\\n${MEMORY_PASSED}/${MEMORY_TOTAL} passed\\n${{ needs.memory-leak-tests.outputs.leaks-detected || '0' }} leaks detected\\nMemory usage: ${{ needs.memory-leak-tests.outputs.memory-usage || 'N/A' }}"
          elif [[ "${{ needs.memory-leak-tests.result }}" == "skipped" ]]; then
            MEMORY_VALUE="⏭️ Skipped"
          else
            MEMORY_VALUE="❌ Failed"
          fi
          
          # Performance Tests field
          if [[ "${{ needs.performance-tests.result }}" == "success" ]]; then
            PERF_PASSED="${{ needs.performance-tests.outputs.tests-passed || '0' }}"
            PERF_FAILED="${{ needs.performance-tests.outputs.tests-failed || '0' }}"
            PERF_TOTAL=$((PERF_PASSED + PERF_FAILED))
            PERFORMANCE_VALUE="✅ Success\\n${PERF_PASSED}/${PERF_TOTAL} Playwright tests passed\\nPerformance: ${{ needs.performance-tests.outputs.performance-score || '0' }}%\\nAccessibility: ${{ needs.performance-tests.outputs.accessibility-score || '0' }}%\\nSEO: ${{ needs.performance-tests.outputs.seo-score || '0' }}%\\nBest Practices: ${{ needs.performance-tests.outputs.best-practices-score || '0' }}%\\nCore Web Vitals:\\n• LCP: ${{ needs.performance-tests.outputs.lcp-score || '0' }}%\\n• FID: ${{ needs.performance-tests.outputs.fid-score || '0' }}%\\n• CLS: ${{ needs.performance-tests.outputs.cls-score || '0' }}%"
          elif [[ "${{ needs.performance-tests.result }}" == "skipped" ]]; then
            PERFORMANCE_VALUE="⏭️ Skipped"
          else
            PERFORMANCE_VALUE="❌ Failed"
          fi
          
          # E2E Tests field
          if [[ "${{ needs.e2e-tests.result }}" == "success" ]]; then
            E2E_VALUE="✅ Success\\n${{ needs.e2e-tests.outputs.tests-passed || '0' }}/${{ needs.e2e-tests.outputs.tests-total || '0' }} tests passed\\nDuration: ${{ needs.e2e-tests.outputs.test-duration || 'N/A' }}"
          elif [[ "${{ needs.e2e-tests.result }}" == "skipped" ]]; then
            E2E_VALUE="⏭️ Skipped"
          else
            E2E_VALUE="❌ Failed"
          fi
          
          # Build the comprehensive message
          cat << EOF > slack_message.json
          {
            "text": "$STATUS",
            "attachments": [
              {
                "color": "$COLOR",
                "fields": [
                  {
                    "title": "📦 Setup & Dependencies",
                    "value": "$SETUP_VALUE",
                    "short": true
                  },
                  {
                    "title": "🔍 Code Quality & Linting",
                    "value": "$LINT_VALUE",
                    "short": true
                  },
                  {
                    "title": "🧪 Unit Tests",
                    "value": "$UNIT_VALUE",
                    "short": true
                  },
                  {
                    "title": "🔗 Integration Tests",
                    "value": "$INTEGRATION_VALUE",
                    "short": true
                  },
                  {
                    "title": "📸 Snapshot Tests",
                    "value": "$SNAPSHOT_VALUE",
                    "short": true
                  },
                  {
                    "title": "🧠 Memory Leak Tests",
                    "value": "$MEMORY_VALUE",
                    "short": true
                  },
                  {
                    "title": "⚡ Performance Tests",
                    "value": "$PERFORMANCE_VALUE",
                    "short": true
                  },
                  {
                    "title": "🎭 End-to-End Tests",
                    "value": "$E2E_VALUE",
                    "short": true
                  }
                ],
                "footer": "GitHub Actions CI/CD",
                "footer_icon": "https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png",
                "ts": $(date +%s)
              },
              {
                "color": "$COLOR",
                "fields": [
                  {
                    "title": "📝 Details",
                    "value": "• **Commit:** \`${{ github.sha }}\`\\n• **Branch:** \`${{ github.ref_name }}\`\\n• **Author:** ${{ github.actor }}\\n• **Workflow:** <${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|View Details>",
                    "short": false
                  }
                ]
              }
            ]
          }
          EOF
          
          # Send to Slack
          curl -X POST -H 'Content-type: application/json' \
               --data @slack_message.json \
               ${{ env.SLACK_WEBHOOK_URL }}

      - name: 📊 Upload Enhanced Test Summary
        uses: actions/upload-artifact@v4
        with:
          name: comprehensive-test-summary
          path: |
            test-summary.md
            slack_message.json
          retention-days: 30 